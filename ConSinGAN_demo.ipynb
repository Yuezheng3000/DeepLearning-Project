{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConSinGAN_demo.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Install all requirements"
      ],
      "metadata": {
        "id": "lkusJ6zNJbw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "92tUBpBQqaIe",
        "outputId": "41377bef-c07a-4cae-d7fa-45dd405ede56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting absl-py==0.9.0\n",
            "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting albumentations==0.4.3\n",
            "  Downloading albumentations-0.4.3.tar.gz (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 17.6 MB/s \n",
            "\u001b[?25hCollecting cachetools==4.0.0\n",
            "  Downloading cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
            "Collecting certifi==2019.11.28\n",
            "  Downloading certifi-2019.11.28-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.0.4)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.4.2)\n",
            "Collecting future==0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 42.6 MB/s \n",
            "\u001b[?25hCollecting google-auth==1.11.3\n",
            "  Downloading google_auth-1.11.3-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib==0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting grpcio==1.27.2\n",
            "  Downloading grpcio-1.27.2-cp37-cp37m-manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 34.9 MB/s \n",
            "\u001b[?25hCollecting idna==2.9\n",
            "  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting imageio==2.8.0\n",
            "  Downloading imageio-2.8.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.1 MB/s \n",
            "\u001b[?25hCollecting imgaug==0.2.6\n",
            "  Downloading imgaug-0.2.6.tar.gz (631 kB)\n",
            "\u001b[K     |████████████████████████████████| 631 kB 58.2 MB/s \n",
            "\u001b[?25hCollecting joblib==0.14.1\n",
            "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting kiwisolver==1.1.0\n",
            "  Downloading kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.2 MB/s \n",
            "\u001b[?25hCollecting Markdown==3.2.1\n",
            "  Downloading Markdown-3.2.1-py2.py3-none-any.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.0.3\n",
            "  Downloading matplotlib-3.0.3-cp37-cp37m-manylinux1_x86_64.whl (13.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0 MB 43.6 MB/s \n",
            "\u001b[?25hCollecting networkx==2.4\n",
            "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.0 MB/s \n",
            "\u001b[?25hCollecting numpy==1.15.2\n",
            "  Downloading numpy-1.15.2-cp37-cp37m-manylinux1_x86_64.whl (13.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8 MB 37.8 MB/s \n",
            "\u001b[?25hCollecting oauthlib==3.1.0\n",
            "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 63.1 MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.2.0.32\n",
            "  Downloading opencv_python-4.2.0.32-cp37-cp37m-manylinux1_x86_64.whl (28.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless==4.2.0.32\n",
            "  Downloading opencv_python_headless-4.2.0.32-cp37-cp37m-manylinux1_x86_64.whl (21.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.6 MB 282 kB/s \n",
            "\u001b[?25hCollecting Pillow==5.3.0\n",
            "  Downloading Pillow-5.3.0-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 48.9 MB/s \n",
            "\u001b[?25hCollecting protobuf==3.11.3\n",
            "  Downloading protobuf-3.11.3-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 26)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 27)) (0.2.8)\n",
            "Collecting pyparsing==2.4.6\n",
            "  Downloading pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.7.3\n",
            "  Downloading python_dateutil-2.7.3-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting PyWavelets==1.1.1\n",
            "  Downloading PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 46.8 MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.3.1\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 32)) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 33)) (1.3.0)\n",
            "Collecting rsa==4.0\n",
            "  Downloading rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting scikit-image==0.15.0\n",
            "  Downloading scikit_image-0.15.0-cp37-cp37m-manylinux1_x86_64.whl (26.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.2.post1\n",
            "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 55.9 MB/s \n",
            "\u001b[?25hCollecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 45.9 MB/s \n",
            "\u001b[?25hCollecting six==1.14.0\n",
            "  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 39)) (0.0)\n",
            "Collecting tensorboard==2.1.0\n",
            "  Downloading tensorboard-2.1.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 45.1 MB/s \n",
            "\u001b[?25hCollecting torch==1.1.0\n",
            "  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 676.9 MB 3.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.2.2.post3\n",
            "  Downloading torchvision-0.2.2.post3-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.27.0\n",
            "  Downloading tqdm-4.27.0-py2.py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting urllib3==1.25.8\n",
            "  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 47.9 MB/s \n",
            "\u001b[?25hCollecting Werkzeug==1.0.0\n",
            "  Downloading Werkzeug-1.0.0-py2.py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.11.3->-r requirements.txt (line 9)) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.1.0->-r requirements.txt (line 40)) (0.37.0)\n",
            "Building wheels for collected packages: absl-py, albumentations, future, imgaug, PyYAML\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121940 sha256=2b3a55587d1423f18fe41d2dd2c69ff8ea65bce8eeae6fa3eae8dcb8e0c6cf1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.3-py3-none-any.whl size=60778 sha256=2ad7e2a9bd8c0b825cbef5f93775fd0e8356321938bffcb7f01a64d227f9e73b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/f4/ab/b45b873b6399eeb93386bee4f8bddb9ad0e2f54d34cde20861\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=b806a1678df9990331a8568d3145d169e9301d14f275c28d349d8afcf2640f57\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-py3-none-any.whl size=654020 sha256=6b622875e650569ec07d08c108c2db881b404120a6ba91ea9764bf4c368699d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/72/98/3ebfdba1069a9a8eaaa7ae7265cfd67d63ef0197aaee2e5f9c\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44635 sha256=dbc22a8c32a9aab7c0a3359fa1fb06e0f07e06e4b4a09e28f5cd29b2b341c643\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
            "Successfully built absl-py albumentations future imgaug PyYAML\n",
            "Installing collected packages: six, urllib3, python-dateutil, pyparsing, Pillow, numpy, kiwisolver, idna, cycler, certifi, scipy, rsa, PyWavelets, oauthlib, networkx, matplotlib, imageio, cachetools, scikit-image, joblib, google-auth, Werkzeug, torch, scikit-learn, PyYAML, protobuf, opencv-python, Markdown, imgaug, grpcio, google-auth-oauthlib, absl-py, tqdm, torchvision, tensorboard, opencv-python-headless, future, albumentations\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.6\n",
            "    Uninstalling pyparsing-3.0.6:\n",
            "      Successfully uninstalled pyparsing-3.0.6\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.3.2\n",
            "    Uninstalling kiwisolver-1.3.2:\n",
            "      Successfully uninstalled kiwisolver-1.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.10.8\n",
            "    Uninstalling certifi-2021.10.8:\n",
            "      Successfully uninstalled certifi-2021.10.8\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.8\n",
            "    Uninstalling rsa-4.8:\n",
            "      Successfully uninstalled rsa-4.8\n",
            "  Attempting uninstall: PyWavelets\n",
            "    Found existing installation: PyWavelets 1.2.0\n",
            "    Uninstalling PyWavelets-1.2.0:\n",
            "      Successfully uninstalled PyWavelets-1.2.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.1.1\n",
            "    Uninstalling oauthlib-3.1.1:\n",
            "      Successfully uninstalled oauthlib-3.1.1\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 4.2.4\n",
            "    Uninstalling cachetools-4.2.4:\n",
            "      Successfully uninstalled cachetools-4.2.4\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.35.0\n",
            "    Uninstalling google-auth-1.35.0:\n",
            "      Successfully uninstalled google-auth-1.35.0\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Attempting uninstall: Markdown\n",
            "    Found existing installation: Markdown 3.3.6\n",
            "    Uninstalling Markdown-3.3.6:\n",
            "      Successfully uninstalled Markdown-3.3.6\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.42.0\n",
            "    Uninstalling grpcio-1.42.0:\n",
            "      Successfully uninstalled grpcio-1.42.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.12.0\n",
            "    Uninstalling absl-py-0.12.0:\n",
            "      Successfully uninstalled absl-py-0.12.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.15.2 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.15.2 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.1.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.1.0 which is incompatible.\n",
            "tensorflow 2.7.0 requires tensorboard~=2.6, but you have tensorboard 2.1.0 which is incompatible.\n",
            "tensorflow-metadata 1.4.0 requires protobuf<4,>=3.13, but you have protobuf 3.11.3 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.27.0 which is incompatible.\n",
            "pymc3 3.11.4 requires cachetools>=4.2.1, but you have cachetools 4.0.0 which is incompatible.\n",
            "pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.15.2 which is incompatible.\n",
            "pyarrow 3.0.0 requires numpy>=1.16.6, but you have numpy 1.15.2 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.3 which is incompatible.\n",
            "plotnine 0.6.0 requires numpy>=1.16.0, but you have numpy 1.15.2 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.27.0 which is incompatible.\n",
            "pandas 1.1.5 requires numpy>=1.15.4, but you have numpy 1.15.2 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.3 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.15.2 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.15.2 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.15.2 which is incompatible.\n",
            "jax 0.2.25 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "googleapis-common-protos 1.53.0 requires protobuf>=3.12.0, but you have protobuf 3.11.3 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth>=1.17.2, but you have google-auth 1.11.3 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.14.0 which is incompatible.\n",
            "google-api-python-client 1.12.8 requires google-auth>=1.16.0, but you have google-auth 1.11.3 which is incompatible.\n",
            "google-api-core 1.26.3 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 1.11.3 which is incompatible.\n",
            "google-api-core 1.26.3 requires protobuf>=3.12.0, but you have protobuf 3.11.3 which is incompatible.\n",
            "fbprophet 0.7.1 requires numpy>=1.15.4, but you have numpy 1.15.2 which is incompatible.\n",
            "fbprophet 0.7.1 requires python-dateutil>=2.8.0, but you have python-dateutil 2.7.3 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.27.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.15.2 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 5.3.0 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.15.2 which is incompatible.\u001b[0m\n",
            "Successfully installed Markdown-3.2.1 Pillow-5.3.0 PyWavelets-1.1.1 PyYAML-5.3.1 Werkzeug-1.0.0 absl-py-0.9.0 albumentations-0.4.3 cachetools-4.0.0 certifi-2019.11.28 cycler-0.10.0 future-0.18.2 google-auth-1.11.3 google-auth-oauthlib-0.4.1 grpcio-1.27.2 idna-2.9 imageio-2.8.0 imgaug-0.2.6 joblib-0.14.1 kiwisolver-1.1.0 matplotlib-3.0.3 networkx-2.4 numpy-1.15.2 oauthlib-3.1.0 opencv-python-4.2.0.32 opencv-python-headless-4.2.0.32 protobuf-3.11.3 pyparsing-2.4.6 python-dateutil-2.7.3 rsa-4.0 scikit-image-0.15.0 scikit-learn-0.22.2.post1 scipy-1.1.0 six-1.14.0 tensorboard-2.1.0 torch-1.1.0 torchvision-0.2.2.post3 tqdm-4.27.0 urllib3-1.25.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cycler",
                  "dateutil",
                  "google",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pyparsing",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unconditional Generation\n",
        "Generally train a model with a given image, e.g. angkorwat.jpg"
      ],
      "metadata": {
        "id": "aAw3Inc3KNU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --train_mode generation --input_name Images/Generation/angkorwat.jpg"
      ],
      "metadata": {
        "id": "29O2T2EZKwWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify Learning Rate Scaling (default is 0.1) to 0.5.\n",
        "\n",
        "Increasing the learning rate scaling will mean that lower stages are trained with a higher learning rate and can, therefore, learn a more faithful model of the original image. "
      ],
      "metadata": {
        "id": "fFY1perzLMxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --train_mode generation --input_name Images/Generation/colusseum.png --lr_scale 0.5"
      ],
      "metadata": {
        "id": "GpyS5I_5LY8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify Number of Trained Stages (default is 0.6) to 7.\n",
        "\n",
        "This can be especially helpful if we want to train on images with higher resolution. "
      ],
      "metadata": {
        "id": "m5mSsG2bLkPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --train_mode generation --input_name Images/Generation/colusseum.png --train_stages 7"
      ],
      "metadata": {
        "id": "MszJlQb1L5Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Outputs\n",
        "The output is saved to TrainedModels/ and we can log the training process with Tensorboard. "
      ],
      "metadata": {
        "id": "O07cAV8HL-F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd TrainedModels/"
      ],
      "metadata": {
        "id": "ifAjAeIlM215"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "Mvwc4BGzM7Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir ."
      ],
      "metadata": {
        "id": "EPQ5Du3OMqGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate more images\n",
        "\n",
        "This will use the model to generate num_samples images in the default as well as scaled resolutions. The results will be saved in a folder Evaluation in the model_dir."
      ],
      "metadata": {
        "id": "vIGq-al1NK9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate_model.py --gpu 0 --model_dir TrainedModels/colusseum/.../ --num_samples 50"
      ],
      "metadata": {
        "id": "LL0uX-NTNgxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unconditional Generation (Images of Arbitrary Sizes)\n",
        "\n",
        "The training, model architecture, loss function, etc stay the same, the only change is the addition of the random noise and a slightly different upsampling routine between the different generator stages."
      ],
      "metadata": {
        "id": "VIBZoDcYNtDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --train_mode retarget --input_name Images/Generation/colusseum.png"
      ],
      "metadata": {
        "id": "xMclJM-qN1qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Harmonization\n",
        "Generally train a default harmonization model with a given image, e.g. scream.jpg"
      ],
      "metadata": {
        "id": "PwPTWXyNN60w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --train_mode harmonization --train_stages 3 --min_size 120 --lrelu_alpha 0.3 --niter 1000 --batch_norm --input_name Images/Harmonization/scream.jpg"
      ],
      "metadata": {
        "id": "RfvrfvHwGMiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a naive image to monitor the progress (only use naive image at test time, not at train time):"
      ],
      "metadata": {
        "id": "mrNYEKngOYom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --train_mode harmonization --train_stages 3 --min_size 120 --lrelu_alpha 0.3 --niter 1000 --batch_norm --input_name Images/Harmonization/scream.jpg --naive_img Images/Harmonization/scream_naive.jpg"
      ],
      "metadata": {
        "id": "QNltCuUzOFoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tune a pre-trained model on a given image (use naive image at train time):"
      ],
      "metadata": {
        "id": "crM9wCXZPK7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --train_mode harmonization --input_name Images/Harmonization/scream.jpg --naive_img Images/Harmonization/scream_naive.jpg --fine_tune --model_dir TrainedModels/scream/..."
      ],
      "metadata": {
        "id": "BY8LXINoTQLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Harmonize a given image with a trained model:"
      ],
      "metadata": {
        "id": "Le8N0hPYPdUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate_model.py --gpu 0 --model_dir TrainedModels/scream/.../ --naive_img Images/Harmonization/scream_naive.jpg"
      ],
      "metadata": {
        "id": "MiBWxDB3Piql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Editing\n",
        "\n",
        "Generally train a default harmonization model with a given image, e.g. stone.png\n",
        "\n",
        "Training for the editing task is the same as for the harmonization task, except that we do it on more stages and with a slightly different image augmentation technique."
      ],
      "metadata": {
        "id": "ZhrcmEAMPvIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --train_mode editing --batch_norm --niter 1000 --input_name Images/Editing/stone.png"
      ],
      "metadata": {
        "id": "oL4naeyAPccU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, an naive image should be used for monitoring training progress:"
      ],
      "metadata": {
        "id": "MKWafVHPQEhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --train_mode editing --batch_norm --niter 1000 --input_name Images/Editing/stone.png --naive_img Images/Editing/stone_edit_1.png"
      ],
      "metadata": {
        "id": "D7h2CUdeTHuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tune a pre-trained model:"
      ],
      "metadata": {
        "id": "N1YHe8-GQJFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train.py --gpu 0 --input_name Images/Editing/stone.png --naive_img Images/Editing/stone_edit_1.png --fine_tune --model_dir TrainedModels/stone/..."
      ],
      "metadata": {
        "id": "4frFAZrsQNtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edit a given image with a trained model:"
      ],
      "metadata": {
        "id": "5s05JXIOQSQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate_model.py --gpu 0 --model_dir TrainedModels/stone/.../ --naive_img Images/Harmonization/stone_edit_1.png"
      ],
      "metadata": {
        "id": "4m05WETsQUWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Citation\n"
      ],
      "metadata": {
        "id": "PyE9TR-xQeyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@inproceedings{hinz2021improved,\n",
        "    author    = {Hinz, Tobias and Fisher, Matthew and Wang, Oliver and Wermter, Stefan},\n",
        "    title     = {Improved Techniques for Training Single-Image GANs},\n",
        "    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},\n",
        "    month     = {January},\n",
        "    year      = {2021},\n",
        "    pages     = {1300--1309}\n",
        "}"
      ],
      "metadata": {
        "id": "XzVXDr1kQnbR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}